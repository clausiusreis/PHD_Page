
<html>
	<head>
	<meta charset='utf-8'>
	<style>
	#proj {
		width: 940px;
	}
	#projimg {
		position:relative;
		width: 138px;
		float: left;
	}
	#projtext {
		position: relative;
		width: 800px;
		float: left;
	}
	</style>
	</head>
	<body>
		<div align="center">
			<h1>PHD Projects - Clausius Duque Reis</h1>

			<div id="proj">
				<div id="projimg">
					<hr>
					<a href="https://github.com/clausiusreis/IV-2018">
						<img src="./img/iv2018.png">
					</a>
				</div>
				<div id="projtext" align="justify">
					<hr>
					<a href="https://github.com/clausiusreis/IV-2018">
					<strong>A Visualization Framework for Feature Investigation in Soundscape Recordings.</strong>
					</a><BR>
						Studies in soundscape ecology can generate large volumes of audio recordings collected over extensive time intervals. Extracting information from such data is challenging and time demanding. Important tasks, in this context, are to identify occurrences of acoustic events of interest and find out which combination of audio features are suitable for characterizing specific events or describing a particular soundscape. Researchers in soundscape ecology have been investigating approaches to accomplish such tasks effectively, and there is a demand for tools capable of assisting analysts in investigating large databases of ecological recordings. In this paper we describe a visualization framework for this purpose. The system includes multiple functionalities for soundscape analysis, comprising audio feature extraction, identification of relevant acoustic events by means of visualizations associated with audio playbacks, and event characterization by means of subspace feature analysis, also assisted by visualizations. The system implements a user-driven iterative pipeline that gives domain experts means to search for, identify and characterize acoustic events, gathering insight on which features better describe them and their originating soundscape.  
					<br><br>
					<table>
						<tr>
							<td valign="top" width="250px">
								<strong>Developer(s): </strong> 
								<ul>
									<li>Clausius Duque G. Reis</li>
									<li>Thalisson Nobre Santos</li>
								</ul>
							</td>
							<td valign="top" width="270px">
								<strong>Advisor(s): </strong> 
								<ul>
									<li>Maria Cristina Ferreira de Oliveira</li>
								</ul>
							</td>
						</tr>
					</table>

					<strong>Language: </strong>
						Javascript, PHP, Python
					<br>
					<strong>Library / Framework: </strong>
						D3, JQuery, JQueryUI
					<br>				
					<strong>Data from: </strong>
						The database used on the tests was recorded on the Costa Rica Forest from the period of Mar/06/2015 to Mar/19/2015. Was provided from Professor Bryan Pijanowsky.
					<br>
					<strong>Funding: </strong>
        				CAPES, CNPq (301847/2017-7) and FAPESP (Project 2017/05838-3)
				</div>			
			</div>
			
			<div id="proj">
				<div id="projimg">
					<hr>
					<a href="https://github.com/clausiusreis/FAV-Signature">
						<img src="./img/FAV.png">
					</a>
				</div>
				<div id="projtext" align="justify">
					<hr>
					<a href="https://github.com/clausiusreis/FAV-Signature">
					<strong>Automatic Detection of Vessel Signatures in Audio Recordings with Spectral Amplitude Variation Signature.</strong>
					</a><BR>
						Sound emissions by ships and boats can strongly impact marine life, with potential to affect communications, breeding and prey and predator relationships. Automatic detection of boat signatures in underwater audio recordings is thus an important task. Automated solutions are particularly relevant for monitoring preservation areas where the presence of watercrafts is usually regulated. The task is particularly challenging because it requires distinguishing multiple overlapping acoustic events in typically noisy audio recordings. In this paper we introduce an algorithm for boat and ship detection which computes an acoustic signature that captures the variance in the frequency amplitudes observed over the duration of the signal. We evaluated the algorithm on a database of underwater recordings collected at two conservation areas in the State of SÃ£o Paulo, Brazil, with very good results, and also compared it with an existing solution. Besides being effective, the algorithm requires limited user input and no parameter fine tuning to handle diverse situations. It thus provides a solution to automate the detection of vessels, with potential applications for monitoring marine preservation areas.
					<br><br>
					<table>
						<tr>
							<td valign="top" width="250px">
								<strong>Developer(s): </strong> 
								<ul>
									<li>Clausius Duque G. Reis</li>
								</ul>
							</td>
							<td valign="top" width="270px">
								<strong>Advisor(s): </strong> 
								<ul>
									<li>Maria Cristina Ferreira de Oliveira</li>
								</ul>
							</td>
						</tr>
					</table>

					<strong>Language: </strong>
						Python
					<br>
					<strong>Funding: </strong>
        				CNPq (301847/2017-7) and FAPESP (2017/05838-3 and 2016/02175-0)
				</div>			
			</div>
			
			<div id="proj">
				<div id="projimg">
					<hr>
					<a href="https://github.com/clausiusreis/Seecology">
						<img src="./img/Seecology.png">
					</a>
				</div>
				<div id="projtext" align="justify">
					<hr>
					<a href="https://github.com/clausiusreis/Seecology">
					<strong>Seecology - A visualization framework for acoustic ecology applications.</strong>
					</a><BR>
						The research field of Acoustic Ecology produces a large amount of data that need to be processed, concatenated, normalized, etc. Therefore, tools that capable to work with these volumes of data are needed.
						The Seecology framework provides a stand-alone solution for the extraction, processing and visualization of acoustic ecology data, allowing for custom settings for indivisual features and extraction for different sample window lenghts, from 1 second to the entire file duration.<br><br>
						The novel algorithm for boat signature detection on underwater recordings (Frequency Amplitude Variation - FAV), is also available on this framework, allowing the detection and visualization of both the boat signatures and their detection over the period of the recordings.<br><br>
						The extracted data can be easilly accessed by means of interactive visualizations with media player capabilities, so the user can listen to the original audio alongside the data visualization.
					<br><br>
					<table>
						<tr>
							<td valign="top" width="250px">
								<strong>Developer(s): </strong> 
								<ul>
									<li>Clausius Duque G. Reis</li>
								</ul>
							</td>
							<td valign="top" width="270px">
								<strong>Advisor(s): </strong> 
								<ul>
									<li>Maria Cristina Ferreira de Oliveira</li>
								</ul>
							</td>
						</tr>
					</table>

					<strong>Language: </strong>
						Javascript, Python
					<br>
					<strong>Library / Framework: </strong>
						D3, JQuery, JQueryUI, Flask
					<br>				
					<strong>Funding: </strong>
        				CAPES, CNPq (301847/2017-7) and FAPESP (Project 2017/05838-3)
        			<br><br>
				</div>
			</div>			

		</div>		
	</body>
</html>
